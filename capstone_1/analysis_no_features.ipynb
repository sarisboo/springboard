{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TL;DR In-depth Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikihow_subset = pd.read_csv('./datasets/wikihow_sep_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>words</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "      <th>title_sim_categories</th>\n",
       "      <th>help</th>\n",
       "      <th>...</th>\n",
       "      <th>want</th>\n",
       "      <th>many</th>\n",
       "      <th>ask</th>\n",
       "      <th>good</th>\n",
       "      <th>find</th>\n",
       "      <th>work</th>\n",
       "      <th>go</th>\n",
       "      <th>include</th>\n",
       "      <th>important</th>\n",
       "      <th>know</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sell yourself first</td>\n",
       "      <td>yes</td>\n",
       "      <td>['Sell', 'yourself', 'first']</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "      <td>3</td>\n",
       "      <td>1.725841</td>\n",
       "      <td>0.828910</td>\n",
       "      <td>Strong</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Before doing anything else, stop and sum up yo...</td>\n",
       "      <td>no</td>\n",
       "      <td>['Before', 'doing', 'anything', 'else,', 'stop...</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "      <td>12</td>\n",
       "      <td>3.421057</td>\n",
       "      <td>0.806864</td>\n",
       "      <td>Strong</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Now, think about how to translate that to an o...</td>\n",
       "      <td>no</td>\n",
       "      <td>['Now,', 'think', 'about', 'how', 'to', 'trans...</td>\n",
       "      <td>How to Sell Fine Art Online</td>\n",
       "      <td>11</td>\n",
       "      <td>3.064425</td>\n",
       "      <td>0.857768</td>\n",
       "      <td>Strong</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                           sentence is_summary  \\\n",
       "0        0                                Sell yourself first        yes   \n",
       "1        0  Before doing anything else, stop and sum up yo...         no   \n",
       "2        0  Now, think about how to translate that to an o...         no   \n",
       "\n",
       "                                               words  \\\n",
       "0                      ['Sell', 'yourself', 'first']   \n",
       "1  ['Before', 'doing', 'anything', 'else,', 'stop...   \n",
       "2  ['Now,', 'think', 'about', 'how', 'to', 'trans...   \n",
       "\n",
       "                         title  sentence_len  tfidf_score  title_similarity  \\\n",
       "0  How to Sell Fine Art Online             3     1.725841          0.828910   \n",
       "1  How to Sell Fine Art Online            12     3.421057          0.806864   \n",
       "2  How to Sell Fine Art Online            11     3.064425          0.857768   \n",
       "\n",
       "  title_sim_categories  help  ...  want  many  ask  good  find  work  go  \\\n",
       "0               Strong     0  ...     0     0    0     0     0     0   0   \n",
       "1               Strong     0  ...     0     0    0     0     0     0   0   \n",
       "2               Strong     0  ...     0     0    0     0     0     0   0   \n",
       "\n",
       "   include  important  know  \n",
       "0        0          0     0  \n",
       "1        0          0     0  \n",
       "2        0          0     0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikihow_subset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize `is_summary`\n",
    "wikihow_subset['summary_id'] = wikihow_subset['is_summary'].apply(lambda x: 1 if x == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to keep\n",
    "features = wikihow_subset[['text_id','sentence', 'summary_id','sentence_len','tfidf_score', 'title_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83438\n",
       "1    16562\n",
       "Name: summary_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts of the classes to get an idea of the null accuracy\n",
    "features.summary_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83438"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing null accuracy\n",
    "null_accuracy = 83438/(16562+83438)\n",
    "null_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Cross-Validation on CountVectorizer and MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "X = features[['sentence', 'sentence_len', 'tfidf_score','title_similarity']]\n",
    "y = features['summary_id']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_feat = X_train['sentence']\n",
    "X_test_no_feat = X_test['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Cross Validation for the best combination of parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__min_df': (2, 5, 10, 15, 20, 30, 40, 50),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'nb__alpha': (0.1, 1, 5, 10, 50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters for both the feature extraction and the classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'nb']\n",
      "parameters:\n",
      "{'vect__min_df': (2, 5, 10, 15, 20, 30, 40, 50), 'vect__ngram_range': ((1, 1), (1, 2)), 'nb__alpha': (0.1, 1, 5, 10, 50)}\n",
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.845\n",
      "Best parameters set:\n",
      "\tnb__alpha: 1\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "grid_search.fit(X_train_no_feat, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a BOW model with the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "Xtrain_dtm = vectorizer.fit_transform(X_train_no_feat)\n",
    "Xtrain_dtm_dense = Xtrain_dtm.toarray() \n",
    "len(Xtrain_dtm_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x100222 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 676598 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vectorizer.transform(X_test_no_feat)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Multinomial Naive Bayes with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "best_nb.fit(Xtrain_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = best_nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[24356   604]\n",
      " [ 2987  2053]]\n"
     ]
    }
   ],
   "source": [
    "# calculate performance metrics\n",
    "from sklearn import metrics\n",
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, y_pred_class)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     24960\n",
      "           1       0.77      0.41      0.53      5040\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.83      0.69      0.73     30000\n",
      "weighted avg       0.87      0.88      0.86     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, y_pred_class)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low recall, high precision -> classifier is very picky and misses a lot of actual summary sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {metrics.accuracy_score(y_test, y_pred_class)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs slightly better than the null accuracy, we will need to do some parameter tuning and add some features in order to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79156</th>\n",
       "      <td>For flat scars, choose a color that neutralize...</td>\n",
       "      <td>10</td>\n",
       "      <td>2.920918</td>\n",
       "      <td>0.782336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31631</th>\n",
       "      <td>Don t forget to dab the alum block in cold wat...</td>\n",
       "      <td>13</td>\n",
       "      <td>3.386033</td>\n",
       "      <td>0.830021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>Watch how much salt you use while cooking don ...</td>\n",
       "      <td>18</td>\n",
       "      <td>3.807531</td>\n",
       "      <td>0.817822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>Roast cauliflower with olive oil, turmeric, cu...</td>\n",
       "      <td>12</td>\n",
       "      <td>3.392271</td>\n",
       "      <td>0.486347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>If you learn about more than 1 casino in your ...</td>\n",
       "      <td>25</td>\n",
       "      <td>4.445260</td>\n",
       "      <td>0.879589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentence_len  \\\n",
       "79156  For flat scars, choose a color that neutralize...            10   \n",
       "31631  Don t forget to dab the alum block in cold wat...            13   \n",
       "26303  Watch how much salt you use while cooking don ...            18   \n",
       "5223   Roast cauliflower with olive oil, turmeric, cu...            12   \n",
       "866    If you learn about more than 1 casino in your ...            25   \n",
       "\n",
       "       tfidf_score  title_similarity  \n",
       "79156     2.920918          0.782336  \n",
       "31631     3.386033          0.830021  \n",
       "26303     3.807531          0.817822  \n",
       "5223      3.392271          0.486347  \n",
       "866       4.445260          0.879589  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positive summaries (non summaries incorrectly classified as summaries)\n",
    "X_test[y_pred_class > y_test].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35795</th>\n",
       "      <td>Drink more green tea</td>\n",
       "      <td>4</td>\n",
       "      <td>1.940366</td>\n",
       "      <td>0.465952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Choose the same last name as your parent s sta...</td>\n",
       "      <td>12</td>\n",
       "      <td>2.959494</td>\n",
       "      <td>0.823162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99089</th>\n",
       "      <td>Cut up carrots</td>\n",
       "      <td>3</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.595426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87070</th>\n",
       "      <td>Brush your teeth</td>\n",
       "      <td>3</td>\n",
       "      <td>1.704851</td>\n",
       "      <td>0.562389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82585</th>\n",
       "      <td>Clean your tongue once per day</td>\n",
       "      <td>6</td>\n",
       "      <td>2.341083</td>\n",
       "      <td>0.760526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  sentence_len  \\\n",
       "35795                               Drink more green tea             4   \n",
       "575    Choose the same last name as your parent s sta...            12   \n",
       "99089                                     Cut up carrots             3   \n",
       "87070                                   Brush your teeth             3   \n",
       "82585                     Clean your tongue once per day             6   \n",
       "\n",
       "       tfidf_score  title_similarity  \n",
       "35795     1.940366          0.465952  \n",
       "575       2.959494          0.823162  \n",
       "99089     1.732051          0.595426  \n",
       "87070     1.704851          0.562389  \n",
       "82585     2.341083          0.760526  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negative summaries (summaries incorrectly classified as non summaries)\n",
    "X_test[y_pred_class < y_test].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999991e-01, 8.71325601e-09],\n",
       "       [1.00000000e+00, 8.61438939e-21],\n",
       "       [1.04333470e-01, 8.95666530e-01],\n",
       "       ...,\n",
       "       [9.88583994e-01, 1.14160060e-02],\n",
       "       [1.00000000e+00, 1.08789904e-11],\n",
       "       [4.69466275e-01, 5.30533725e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left: proba the class is 0, Right: proba the class is 1 \n",
    "best_nb.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9342752332303115"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = best_nb.predict_proba(X_test_dtm)[:, 1]\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which words are more prone to be in a summary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vectorizer.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  2., 84., ...,  2.,  6.,  2.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "best_nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100222)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "best_nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  2., 84., ...,  2.,  6.,  2.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all summary sentences\n",
    "non_summary_token_count = best_nb.feature_count_[0, :]\n",
    "non_summary_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all non-summary sentences\n",
    "summary_token_count = best_nb.feature_count_[1, :]\n",
    "summary_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>non_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00 year</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000 americans</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               summary  non_summary\n",
       "token                              \n",
       "00                 0.0          6.0\n",
       "00 year            0.0          2.0\n",
       "000                0.0         84.0\n",
       "000 000            0.0          4.0\n",
       "000 americans      0.0          2.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'summary':summary_token_count, 'non_summary':non_summary_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>non_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the team</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use acupressure</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foods including</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>move upwards</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal</th>\n",
       "      <td>21.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 summary  non_summary\n",
       "token                                \n",
       "the team             0.0          2.0\n",
       "use acupressure      1.0          2.0\n",
       "foods including      0.0          8.0\n",
       "move upwards         0.0          2.0\n",
       "personal            21.0        130.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58478., 11522.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "best_nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Performing Cross Validation for the best combination of parameters\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [80, 90, 100, 110]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [8, 10, 12]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "param_grid = {\n",
    "    #try with 500\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth':[4,5,6,7,8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameters for both the feature extraction and the classifier\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
    "CV_rfc.fit(Xtrain_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 200}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(random_state=42, n_estimators= 200, max_depth=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(Xtrain_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class_rf = rf.predict(X_test_dtm)\n",
    "y_pred_class_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[24960     0]\n",
      " [ 5040     0]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, y_pred_class_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     24960\n",
      "           1       0.00      0.00      0.00      5040\n",
      "\n",
      "    accuracy                           0.83     30000\n",
      "   macro avg       0.42      0.50      0.45     30000\n",
      "weighted avg       0.69      0.83      0.76     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, y_pred_class_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes Classifier seems to to an overall better job than Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide X_train by groups of summary sentences and non summary sentences\n",
    "X_train.head()\n",
    "X_y_train_df= pd.DataFrame(data=X_train_no_feat, columns= ['sentence'])\n",
    "X_y_train_df['summary_id'] = y_train\n",
    "X_train_sum = X_y_train_df[X_y_train_df['summary_id']==1]['sentence']\n",
    "X_train_no_sum = X_y_train_df[X_y_train_df['summary_id']==0]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Cross Validation for the best combination of parameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('tfidf_nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__min_df': (2, 5, 10, 15, 20, 30, 40, 50),\n",
    "    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf_nb__alpha': (0.1, 1, 5, 10, 50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters for both the feature extraction and the classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'tfidf_nb']\n",
      "parameters:\n",
      "{'tfidf__min_df': (2, 5, 10, 15, 20, 30, 40, 50), 'tfidf__ngram_range': ((1, 1), (1, 2)), 'tfidf__use_idf': (True, False), 'tfidf_nb__alpha': (0.1, 1, 5, 10, 50)}\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.849\n",
      "Best parameters set:\n",
      "\ttfidf__min_df: 2\n",
      "\ttfidf__ngram_range: (1, 2)\n",
      "\ttfidf__use_idf: True\n",
      "\ttfidf_nb__alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "grid_search.fit(X_train_no_feat, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Representing text as tfidf score of different unigrams and bigrams \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tfidf=TfidfVectorizer(min_df =2, ngram_range=(1,2), use_idf = True)\n",
    "\n",
    "#Fitting the vectorizer to summary and non summary sentences separately\n",
    "tfidf.fit(X_train_no_sum, X_train_sum)\n",
    "tf_idf_vectors = tfidf.transform(X_train_no_feat)\n",
    "\n",
    "#Converting the sparse matrix into a dense matrix\n",
    "tf_idf_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf.transform(X_test_no_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use MultinomialNB with tf-idf \n",
    "\n",
    "Should we be using Naive Bayes with tf-idf ? naive bayes works better with integers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf = MultinomialNB(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfidf.fit(tf_idf_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf_pred = nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762333333333333"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "metrics.accuracy_score(y_test, nb_tfidf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[24604   356]\n",
      " [ 3357  1683]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, nb_tfidf_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93     24960\n",
      "           1       0.83      0.33      0.48      5040\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.85      0.66      0.70     30000\n",
      "weighted avg       0.87      0.88      0.85     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, nb_tfidf_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tf-idf with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Cross Validation for the best combination of parameters\n",
    "\n",
    "tfidf_rfc = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "param_grid = {\n",
    "    \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth':[4,5,6,7,8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best parameters for both the feature extraction and the classifier\n",
    "tfidf_CV_rfc = GridSearchCV(estimator=tfidf_rfc, param_grid=param_grid, cv=5)\n",
    "tfidf_CV_rfc.fit(tf_idf_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 200}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use best params for rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf = RandomForestClassifier(random_state=42,n_jobs=-1,max_depth= 4, n_estimators= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tfidf.fit(tf_idf_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tfidf_pred = rf_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "metrics.accuracy_score(y_test, rf_tfidf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[24960     0]\n",
      " [ 5040     0]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, rf_tfidf_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91     24960\n",
      "           1       0.00      0.00      0.00      5040\n",
      "\n",
      "    accuracy                           0.83     30000\n",
      "   macro avg       0.42      0.50      0.45     30000\n",
      "weighted avg       0.69      0.83      0.76     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report\n",
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, rf_tfidf_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Dataframes to add more features later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf_idf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tfidf sparse matrices  \n",
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('./datasets/train_sparse_matrix.npz', tf_idf_vectors)\n",
    "scipy.sparse.save_npz('./datasets/test_sparse_matrix.npz', X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save feature names \n",
    "import pickle\n",
    "with open(\"tfidf_features.txt\", 'wb') as f:\n",
    "    pickle.dump(tfidf.get_feature_names(), f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save training and testing dataframes (without tfidf)\n",
    "X_train.to_csv('./datasets/wikihow_X_train.csv', index=False)\n",
    "X_test.to_csv('./datasets/wikihow_X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save labels  \n",
    "y_train.to_csv('./datasets/wikihow_y_train.csv', index=False)\n",
    "y_test.to_csv('./datasets/wikihow_y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
