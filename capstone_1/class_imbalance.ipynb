{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting for class imbalance\n",
    "\n",
    "Naive Bayes classifier makes prediction using the class prior it learned from the ratio of classes in the training data. Large discrepancy of class ratios between training and validation sets leads to the inaccurate estimation of class prior which decrease the predictive performance of naive Bayes classifier.\n",
    "\n",
    "## Oversampling the minority class\n",
    "\n",
    "Oversampling balances the dataset by increasing the size of the minority class. A balanced new dataset can then be retrieved for further modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy.sparse\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from eval_funcs import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikihow = pd.read_csv('./datasets/wikihow_sep_features.csv')\n",
    "wikihow_subset = pd.read_csv('./datasets/wikihow_sep_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picking 3 random new articles text_id = 10115, 146523,53935 \n",
    "text_1_df = wikihow[wikihow['text_id'] == 10115]\n",
    "text_2_df = wikihow[wikihow['text_id'] == 146523]\n",
    "text_3_df = wikihow[wikihow['text_id'] == 53935]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 3 texts \n",
    "text_1_df.to_csv('./datasets/text_1.csv', index = False)\n",
    "text_2_df.to_csv('./datasets/text_2.csv', index = False)\n",
    "text_3_df.to_csv('./datasets/text_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sparse matrices\n",
    "tf_idf_vectors = scipy.sparse.load_npz('./datasets/train_sparse_matrix.npz')\n",
    "X_test_tfidf = scipy.sparse.load_npz('./datasets/test_sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tfidf feature names list\n",
    "# if file exists we have already pickled a list\n",
    "if os.path.isfile(\"tfidf_features.txt\"):\n",
    "    with open(\"tfidf_features.txt\", 'rb') as f:\n",
    "        tfidf_feature_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load X_train and X_test\n",
    "X_train = pd.read_csv('./datasets/wikihow_X_train.csv') \n",
    "X_test = pd.read_csv('./datasets/wikihow_X_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load y_train and y_test \n",
    "y_train = pd.read_csv('./datasets/wikihow_y_train.csv', header = None) \n",
    "y_test = pd.read_csv('./datasets/wikihow_y_test.csv', header = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= y_train.rename(columns={0:'is_summary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185853</td>\n",
       "      <td>Your lip balm could be doing more harm than go...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.787809</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206476</td>\n",
       "      <td>However, always practice each mudra for minute...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.970394</td>\n",
       "      <td>0.785855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187976</td>\n",
       "      <td>In severe cases, back problems like slipped di...</td>\n",
       "      <td>11</td>\n",
       "      <td>3.497105</td>\n",
       "      <td>0.725264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172941</td>\n",
       "      <td>Learn to laugh at yourself</td>\n",
       "      <td>5</td>\n",
       "      <td>3.696760</td>\n",
       "      <td>0.716063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190532</td>\n",
       "      <td>Special tests, such as a skin test, can also b...</td>\n",
       "      <td>20</td>\n",
       "      <td>2.160528</td>\n",
       "      <td>0.755451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                           sentence  sentence_len  \\\n",
       "0   185853  Your lip balm could be doing more harm than go...            14   \n",
       "1   206476  However, always practice each mudra for minute...             9   \n",
       "2   187976  In severe cases, back problems like slipped di...            11   \n",
       "3   172941                         Learn to laugh at yourself             5   \n",
       "4   190532  Special tests, such as a skin test, can also b...            20   \n",
       "\n",
       "   tfidf_score  title_similarity  is_summary  \n",
       "0     1.787809          0.813510           0  \n",
       "1     1.970394          0.785855           0  \n",
       "2     3.497105          0.725264           0  \n",
       "3     3.696760          0.716063           1  \n",
       "4     2.160528          0.755451           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Increasing the size of minority class\n",
    "X_y_train = pd.concat([X_train, y_train], axis=1, sort=False)\n",
    "X_y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11650\n",
       "0    11650\n",
       "Name: is_summary, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide by class\n",
    "\n",
    "from sklearn.utils import resample\n",
    "# Class count\n",
    "count_class_0, count_class_1 = X_y_train.is_summary.value_counts()\n",
    "\n",
    "non_summary = X_y_train[X_y_train['is_summary'] == 0]\n",
    "summary = X_y_train[X_y_train['is_summary'] == 1]\n",
    "\n",
    "# still using our separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "summary_downsampled = resample(non_summary,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(summary), # match minority n\n",
    "                                random_state = 1337) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([summary_downsampled, summary])\n",
    "\n",
    "# checking counts\n",
    "downsampled.is_summary.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set negative values to a very low value near zero \n",
    "#to keep a lower bound and be able to feed the matrix to the Naive Bayes classifier. \n",
    "downsampled[downsampled['title_similarity'] < 0] =0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_id, sentence, sentence_len, tfidf_score, title_similarity, is_summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled[downsampled['title_similarity'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the adjusted dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8401     0\n",
       "3839     0\n",
       "32714    0\n",
       "52937    0\n",
       "61822    0\n",
       "Name: is_summary, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = downsampled['is_summary']\n",
    "y_train = y_train.astype(int)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8401</th>\n",
       "      <td>68042.0</td>\n",
       "      <td>Take a lot of vitamin D</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.475049</td>\n",
       "      <td>0.734723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>96150.0</td>\n",
       "      <td>As with the rest of your recovery, give it tim...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.739929</td>\n",
       "      <td>0.886377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32714</th>\n",
       "      <td>194328.0</td>\n",
       "      <td>If your symptoms are long lasting or particula...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.826643</td>\n",
       "      <td>0.780749</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52937</th>\n",
       "      <td>83199.0</td>\n",
       "      <td>The exact amount will depend on state guidelin...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.348581</td>\n",
       "      <td>0.785848</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61822</th>\n",
       "      <td>186005.0</td>\n",
       "      <td>The BRAT diet can help to bulk up your stool a...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.709613</td>\n",
       "      <td>0.854378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                           sentence  \\\n",
       "8401    68042.0                            Take a lot of vitamin D   \n",
       "3839    96150.0  As with the rest of your recovery, give it tim...   \n",
       "32714  194328.0  If your symptoms are long lasting or particula...   \n",
       "52937   83199.0  The exact amount will depend on state guidelin...   \n",
       "61822  186005.0  The BRAT diet can help to bulk up your stool a...   \n",
       "\n",
       "       sentence_len  tfidf_score  title_similarity  is_summary  \n",
       "8401            6.0     4.475049          0.734723         0.0  \n",
       "3839           22.0     2.739929          0.886377         0.0  \n",
       "32714          32.0     3.826643          0.780749         0.0  \n",
       "52937          15.0     3.348581          0.785848         0.0  \n",
       "61822          24.0     2.709613          0.854378         0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = downsampled.drop(['is_summary'], axis = 1)\n",
    "X_train['sentence_len'] = X_train['sentence_len'].astype(int)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructing dataframes for analysis \n",
    "X_train_ft = X_train['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validate with adjusted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Cross Validation for the best combination of parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__min_df': (1, 2, 5, 10),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'nb__alpha': (0.1, 1, 5, 10, 50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters for both the feature extraction and the classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'nb']\n",
      "parameters:\n",
      "{'vect__min_df': (1, 2, 5, 10), 'vect__ngram_range': ((1, 1), (1, 2)), 'nb__alpha': (0.1, 1, 5, 10, 50)}\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.753\n",
      "Best parameters set:\n",
      "\tnb__alpha: 1\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "grid_search.fit(X_train_ft, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BOW model and add features to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1), min_df = 5, stop_words='english')\n",
    "vectorizer.fit(X_train_ft, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_len</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8401</th>\n",
       "      <td>68042.0</td>\n",
       "      <td>Take a lot of vitamin D</td>\n",
       "      <td>6</td>\n",
       "      <td>4.475049</td>\n",
       "      <td>0.734723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>96150.0</td>\n",
       "      <td>As with the rest of your recovery, give it tim...</td>\n",
       "      <td>22</td>\n",
       "      <td>2.739929</td>\n",
       "      <td>0.886377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32714</th>\n",
       "      <td>194328.0</td>\n",
       "      <td>If your symptoms are long lasting or particula...</td>\n",
       "      <td>32</td>\n",
       "      <td>3.826643</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52937</th>\n",
       "      <td>83199.0</td>\n",
       "      <td>The exact amount will depend on state guidelin...</td>\n",
       "      <td>15</td>\n",
       "      <td>3.348581</td>\n",
       "      <td>0.785848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61822</th>\n",
       "      <td>186005.0</td>\n",
       "      <td>The BRAT diet can help to bulk up your stool a...</td>\n",
       "      <td>24</td>\n",
       "      <td>2.709613</td>\n",
       "      <td>0.854378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                           sentence  \\\n",
       "8401    68042.0                            Take a lot of vitamin D   \n",
       "3839    96150.0  As with the rest of your recovery, give it tim...   \n",
       "32714  194328.0  If your symptoms are long lasting or particula...   \n",
       "52937   83199.0  The exact amount will depend on state guidelin...   \n",
       "61822  186005.0  The BRAT diet can help to bulk up your stool a...   \n",
       "\n",
       "       sentence_len  tfidf_score  title_similarity  \n",
       "8401              6     4.475049          0.734723  \n",
       "3839             22     2.739929          0.886377  \n",
       "32714            32     3.826643          0.780749  \n",
       "52937            15     3.348581          0.785848  \n",
       "61822            24     2.709613          0.854378  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feats = prediction_preprocessing(X_train)\n",
    "#sent_lengths = np.array(X_train['sentence_len'].values).reshape(-1, 1)\n",
    "#sparse_sent_lengths = scipy.sparse.csr_matrix(sent_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform features \n",
    "sparse_train_mat = vectorizer.transform(X_train_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full_feats = scipy.sparse.hstack([X_train_feats,sparse_train_mat ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same witn test set \n",
    "X_test_feats = prediction_preprocessing(X_test)\n",
    "#sent_lengths_test = np.array(X_test['sentence_len'].values).reshape(-1, 1)\n",
    "#sparse_sent_lengths_test = scipy.sparse.csr_matrix(sent_lengths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ft = X_test['sentence']\n",
    "sparse_test_mat = vectorizer.transform(X_test_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_full_feats = scipy.sparse.hstack([X_test_feats,sparse_test_mat ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed it to the MultinomialNB classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb = MultinomialNB(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_nb.fit(X_train_full_feats, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= best_nb.predict(X_test_full_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[20642  4425]\n",
      " [  677  4256]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89     25067\n",
      "           1       0.49      0.86      0.63      4933\n",
      "\n",
      "    accuracy                           0.83     30000\n",
      "   macro avg       0.73      0.84      0.76     30000\n",
      "weighted avg       0.89      0.83      0.85     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting for class imbalance we obtain one of the highest recalls sacrificing a little bit on precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New text never before seen and make predictions on it \n",
    "text_1_vectors = vectorizer.transform(text_1_df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<337x3948 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1630 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use vectorizer on text_1\n",
    "text_1_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "text_1_df['title_similarity'] = text_1_df.apply(lambda x: get_similarity(x['sentence'], x['title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1_feat = prediction_preprocessing(text_1_df)\n",
    "#sent_lengths = np.array(text_1_df['sentence_len'].values).reshape(-1, 1)\n",
    "#sparse_sent_lengths_text_1 = scipy.sparse.csr_matrix(sent_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1_full_feats = scipy.sparse.hstack([text_1_vectors,text_1_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text_1 = best_nb.predict(text_1_full_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_text_1 = text_1_df[['sentence','is_summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247637</th>\n",
       "      <td>Stop what you re doing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247638</th>\n",
       "      <td>One of the best ways to calm down if you re al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247639</th>\n",
       "      <td>Sometimes, even taking a few seconds before yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247640</th>\n",
       "      <td>Try counting to ten, or taking deep breaths, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247641</th>\n",
       "      <td>Take a break</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  is_summary\n",
       "247637                             Stop what you re doing           1\n",
       "247638  One of the best ways to calm down if you re al...           0\n",
       "247639  Sometimes, even taking a few seconds before yo...           0\n",
       "247640  Try counting to ten, or taking deep breaths, b...           0\n",
       "247641                                       Take a break           1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_text_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248565</th>\n",
       "      <td>Know that everyone has their own unique experi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248566</th>\n",
       "      <td>No one else will grieve in exactly the same wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248567</th>\n",
       "      <td>If you feel like you are reacting differently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248568</th>\n",
       "      <td>Allow yourself to feel your own unique emotion...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248569</th>\n",
       "      <td>There is no typical loss, which means there is...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248570</th>\n",
       "      <td>Sudden losses, such as those due to trauma, ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248889</th>\n",
       "      <td>Acknowledge that there are many kinds of loss</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248890</th>\n",
       "      <td>Death is a loss we must all deal with at some ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248891</th>\n",
       "      <td>However, it is not the only type of loss</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248892</th>\n",
       "      <td>You can mourn the ending of a relationship or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  is_summary  \\\n",
       "248565  Know that everyone has their own unique experi...           1   \n",
       "248566  No one else will grieve in exactly the same wa...           0   \n",
       "248567  If you feel like you are reacting differently ...           0   \n",
       "248568  Allow yourself to feel your own unique emotion...           0   \n",
       "248569  There is no typical loss, which means there is...           0   \n",
       "248570  Sudden losses, such as those due to trauma, ac...           0   \n",
       "248889      Acknowledge that there are many kinds of loss           1   \n",
       "248890  Death is a loss we must all deal with at some ...           0   \n",
       "248891           However, it is not the only type of loss           0   \n",
       "248892  You can mourn the ending of a relationship or ...           0   \n",
       "\n",
       "        predictions  \n",
       "248565            1  \n",
       "248566            1  \n",
       "248567            1  \n",
       "248568            1  \n",
       "248569            1  \n",
       "248570            1  \n",
       "248889            1  \n",
       "248890            1  \n",
       "248891            1  \n",
       "248892            1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New text never before seen and make predictions on it \n",
    "text_2_vectors = vectorizer.transform(text_2_df['sentence'])\n",
    "text_2_df['title_similarity'] = text_2_df.apply(lambda x: get_similarity(x['sentence'], x['title']), axis=1)\n",
    "text_2_feat = prediction_preprocessing(text_2_df)\n",
    "text_2_full_feats = scipy.sparse.hstack([text_2_vectors,text_2_feat])\n",
    "pred_text_2 = best_nb.predict(text_2_full_feats)\n",
    "results_text_2 = text_2_df[['sentence','is_summary']]\n",
    "results_text_2['predictions'] = pred_text_2\n",
    "results_text_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907432</th>\n",
       "      <td>Think about the time commitment of ferret proo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907433</th>\n",
       "      <td>Before you get a ferret, you will need to spen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907434</th>\n",
       "      <td>You will have to run many errands gathering su...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907435</th>\n",
       "      <td>In the event you move, you will have to repeat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907436</th>\n",
       "      <td>Be honest with yourself about whether you have...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence  is_summary  \\\n",
       "907432  Think about the time commitment of ferret proo...           1   \n",
       "907433  Before you get a ferret, you will need to spen...           0   \n",
       "907434  You will have to run many errands gathering su...           0   \n",
       "907435  In the event you move, you will have to repeat...           0   \n",
       "907436  Be honest with yourself about whether you have...           0   \n",
       "\n",
       "        predictions  \n",
       "907432            0  \n",
       "907433            1  \n",
       "907434            1  \n",
       "907435            1  \n",
       "907436            1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New text never before seen and make predictions on it \n",
    "text_3_vectors = vectorizer.transform(text_3_df['sentence'])\n",
    "text_3_df['title_similarity'] = text_3_df.apply(lambda x: get_similarity(x['sentence'], x['title']), axis=1)\n",
    "text_3_feat = prediction_preprocessing(text_3_df)\n",
    "text_3_full_feats = scipy.sparse.hstack([text_3_vectors,text_3_feat])\n",
    "pred_text_3 = best_nb.predict(text_3_full_feats)\n",
    "results_text_3 = text_3_df[['sentence','is_summary']]\n",
    "results_text_3['predictions'] = pred_text_3\n",
    "results_text_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarabouazzaoui/Desktop/springboard/capstone_1/eval_funcs.py:69: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  )/temp_frame[temp_frame['results'] == 1]['text_id'].count()\n",
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting recall distribution \n",
    "recalls = calculate_recall_distribution(X_test, best_nb, y_test)\n",
    "ids = [item[0] for item in recalls ]\n",
    "recalls = [item[1] for item in recalls ]\n",
    "recalls_df = pd.DataFrame(ids , columns=['id'])\n",
    "recalls_df['recalls']= recalls\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.hist(recalls_df['recalls'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarabouazzaoui/Desktop/springboard/capstone_1/eval_funcs.py:69: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  )/temp_frame[temp_frame['results'] == 1]['text_id'].count()\n",
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/sarabouazzaoui/.pyenv/versions/3.7.0/lib/python3.7/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAAI/CAYAAAAYxjIJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df6xn6V3Y9/cnu7FTkhQbduKS3XVnW5a0xk2ENXEcobYkTox/IBapBNlKykJXXbU1hARUsk4quQJFMk0bFyvE7QZvbVfUxnVpWNVOXddArVax8RgSY5sQRsawszXsgI37wwJiePrHfdwMy+zO3bl3771ev17S1T3nOc/3fp/7x9HMvOec8521VgAAAADw+057AQAAAACcDUIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAFXdfL0JM/NA9XXVI2ut5141/u3VK6vfrt6x1vruPf6q6p49/pfXWu/a4y+uvr+6qfrBtdZrrvfet9xyyzp//vwT/Z0AAAAAeAwf/OAHf3Wtde5ax64biqo3Vn+nevPnBmbmz1R3VX9irfWbM/NH9vhzqpdXX1n90ep/nZmv2C/7gerPV5erD8zMg2utjz7eG58/f76LFy8eYokAAAAAHMbM/OJjHbtuKFprvXdmzj9q+D+sXrPW+s0955E9flf11j3+CzNzqXr+PnZprfWxvaC37rmPG4oAAAAAODk3+oyir6j+zZl5/8z8bzPzJ/f4rdVDV827vMceaxwAAACAM+Iwt5491uu+pHpB9Sert83Mv3IcC5qZe6t7q5797Gcfx48EAAAA4BBu9Iqiy9WPrAM/Wf1OdUv1cHX7VfNu22OPNf57rLXuX2tdWGtdOHfums9VAgAAAOBJcKOh6O9Xf6ZqP6z6adWvVg9WL5+Zp8/MHdWd1U9WH6junJk7ZuZpHTzw+sGjLh4AAACA43PdW89m5i3V11S3zMzl6tXVA9UDM/Ph6requ9daq/rIzLytg4dUf7Z65Vrrt/fP+bbqXdVN1QNrrY88Cb8PAAAAADdoDvrO2XThwoV18eLF014GAAAAwFPGzHxwrXXhWsdu9NYzAAAAAJ5ihCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYbj7tBQAAAAC/2/n73nHaS+AaPv6al532Ep50rigCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoDpEKJqZB2bmkZn58DWOfdfMrJm5Ze/PzLxuZi7NzIdm5nlXzb17Zn5+f919vL8GAAAAAEd1mCuK3li9+NGDM3N79aLql64afkl15/66t3r9nvsl1aurP1U9v3r1zDzzKAsHAAAA4HhdNxSttd5bffIah15bfXe1rhq7q3rzOvC+6hkz82XV11bvXmt9cq31qerdXSM+AQAAAHB6bugZRTNzV/XwWusfP+rQrdVDV+1f3mOPNQ4AAADAGXHzE33BzHxR9dc7uO3s2M3MvR3cttazn/3sJ+MtAAAAALiGG7mi6F+t7qj+8cx8vLqt+qmZ+Zeqh6vbr5p72x57rPHfY611/1rrwlrrwrlz525geQAAAADciCccitZaP7PW+iNrrfNrrfMd3Eb2vLXWL1cPVt+8P/3sBdWn11qfqN5VvWhmnrkfYv2iPQYAAADAGXHdUDQzb6n+YfXHZubyzNzzONPfWX2sulT9veo/qlprfbL63uoD++t79hgAAAAAZ8R1n1G01nrFdY6fv2p7Va98jHkPVA88wfUBAAAAcEJu6FPPAAAAAHjqEYoAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqIQiAAAAADahCAAAAIBKKAIAAABgE4oAAAAAqA4RimbmgZl5ZGY+fNXY35qZfzIzH5qZ/3FmnnHVsVfNzKWZ+bmZ+dqrxl+8xy7NzH3H/6sAAAAAcBSHuaLojdWLHzX27uq5a60/Xv3T6lVVM/Oc6uXVV+7X/N2ZuWlmbqp+oHpJ9ZzqFXsuAAAAAGfEdUPRWuu91ScfNfa/rLU+u3ffV922t++q3rrW+s211i9Ul6rn769La62PrbV+q3rrngsAAADAGXEczyj696p/sLdvrR666tjlPfZY4wAAAACcEUcKRTPzN6rPVj90PMupmbl3Zi7OzMUrV64c148FAAAA4DpuOBTNzLdUX1f9xbXW2sMPV7dfNe22PfZY47/HWuv+tdaFtdaFc+fO3ejyAAAAAHiCbigUzcyLq++uvn6t9ZmrDj1YvXxmnj4zd1R3Vj9ZfaC6c2bumJmndfDA6wePtnQAAAAAjtPN15swM2+pvqa6ZWYuV6/u4FPOnl69e2aq3rfW+g/WWh+ZmbdVH+3glrRXrrV+e/+cb6veVd1UPbDW+siT8PsAAAAAcIOuG4rWWq+4xvAbHmf+36z+5jXG31m98wmtDgAAAIATcxyfegYAAADAU4BQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwXTcUzcwDM/PIzHz4qrEvmZl3z8zP7+/P3OMzM6+bmUsz86GZed5Vr7l7z//5mbn7yfl1AAAAALhRh7mi6I3Vix81dl/1nrXWndV79n7VS6o799e91evrICxVr67+VPX86tWfi0sAAAAAnA3XDUVrrfdWn3zU8F3Vm/b2m6pvuGr8zevA+6pnzMyXVV9bvXut9cm11qeqd/d74xMAAAAAp+hGn1H0rLXWJ/b2L1fP2tu3Vg9dNe/yHnuscQAAAADOiCM/zHqttap1DGupambunZmLM3PxypUrx/VjAQAAALiOGw1Fv7JvKWt/f2SPP1zdftW82/bYY43/Hmut+9daF9ZaF86dO3eDywMAAADgibrRUPRg9blPLru7+tGrxr95f/rZC6pP71vU3lW9aGaeuR9i/aI9BgAAAMAZcfP1JszMW6qvqW6ZmcsdfHrZa6q3zcw91S9W37Snv7N6aXWp+kz1rVVrrU/OzPdWH9jzvmet9egHZAMAAABwiq4bitZar3iMQy+8xtxVvfIxfs4D1QNPaHUAAAAAnJgjP8waAAAAgKcGoQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACASigCAAAAYBOKAAAAAKiEIgAAAAA2oQgAAACA6oihaGb+6sx8ZGY+PDNvmZk/MDN3zMz7Z+bSzPzwzDxtz3363r+0j58/jl8AAAAAgONxw6FoZm6t/nJ1Ya313Oqm6uXV91WvXWt9efWp6p79knuqT+3x1+55AAAAAJwRR7317ObqX5iZm6svqj5R/dnq7fv4m6pv2Nt37f328RfOzBzx/QEAAAA4JjccitZaD1f/efVLHQSiT1cfrH59rfXZPe1ydevevrV6aL/2s3v+l97o+wMAAABwvI5y69kzO7hK6I7qj1Z/sHrxURc0M/fOzMWZuXjlypWj/jgAAAAADukot579ueoX1lpX1lr/rPqR6qurZ+xb0apuqx7e2w9Xt1ft419c/dqjf+ha6/611oW11oVz584dYXkAAAAAPBFHCUW/VL1gZr5oP2vohdVHqx+vvnHPubv60b394N5vH/+xtdY6wvsDAAAAcIyO8oyi93fwUOqfqn5m/6z7q79WfefMXOrgGURv2C95Q/Wle/w7q/uOsG4AAAAAjtnN15/y2NZar65e/ajhj1XPv8bc36j+wlHeDwAAAIAnz1FuPQMAAADgKUQoAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKA6YiiamWfMzNtn5p/MzM/OzJ+emS+ZmXfPzM/v78/cc2dmXjczl2bmQzPzvOP5FQAAAAA4Dke9ouj7q/95rfWvVX+i+tnqvuo9a607q/fs/aqXVHfur3ur1x/xvQEAAAA4Rjccimbmi6t/q3pD1Vrrt9Zav17dVb1pT3tT9Q17+67qzevA+6pnzMyX3fDKAQAAADhWR7mi6I7qSvXfzMxPz8wPzswfrJ611vrEnvPL1bP29q3VQ1e9/vIeAwAAAOAMOEoourl6XvX6tdZXVf9v//w2s6rWWqtaT+SHzsy9M3NxZi5euXLlCMsDAAAA4Ik4Sii6XF1ea71/77+9g3D0K5+7pWx/f2Qff7i6/arX37bHfpe11v1rrQtrrQvnzp07wvIAAAAAeCJuOBSttX65emhm/tgeemH10erB6u49dnf1o3v7weqb96efvaD69FW3qAEAAABwym4+4uu/vfqhmXla9bHqWzuIT2+bmXuqX6y+ac99Z/XS6lL1mT0XAAAAgDPiSKForfWPqgvXOPTCa8xd1SuP8n4AAAAAPHmO8owiAAAAAJ5ChCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgE0oAgAAAKASigAAAADYhCIAAAAAKqEIAAAAgO3IoWhmbpqZn56Z/2nv3zEz75+ZSzPzwzPztD3+9L1/aR8/f9T3BgAAAOD4HMcVRd9R/exV+99XvXat9eXVp6p79vg91af2+Gv3PAAAAADOiCOFopm5rXpZ9YN7f6o/W719T3lT9Q17+6693z7+wj0fAAAAgDPgqFcU/ZfVd1e/s/e/tPr1tdZn9/7l6ta9fWv1UNU+/uk9HwAAAIAz4IZD0cx8XfXIWuuDx7ieZubembk4MxevXLlynD8aAAAAgMdxlCuKvrr6+pn5ePXWDm45+/7qGTNz855zW/Xw3n64ur1qH//i6tce/UPXWvevtS6stS6cO3fuCMsDAAAA4Im44VC01nrVWuu2tdb56uXVj621/mL149U37ml3Vz+6tx/c++3jP7bWWjf6/gAAAAAcr+P41LNH+2vVd87MpQ6eQfSGPf6G6kv3+HdW9z0J7w0AAADADbr5+lOub631E9VP7O2PVc+/xpzfqP7CcbwfAAAAAMfvybiiCAAAAIDPQ0IRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAAJVQBAAAAMAmFAEAAABQCUUAAAAAbEIRAAAAANURQtHM3D4zPz4zH52Zj8zMd+zxL5mZd8/Mz+/vz9zjMzOvm5lLM/OhmXnecf0SAAAAABzdUa4o+mz1XWut51QvqF45M8+p7qves9a6s3rP3q96SXXn/rq3ev0R3hsAAACAY3bDoWit9Ym11k/t7f+7+tnq1uqu6k172puqb9jbd1VvXgfeVz1jZr7shlcOAAAAwLE6lmcUzcz56quq91fPWmt9Yh/65epZe/vW6qGrXnZ5jwEAAABwBhw5FM3MH6r+h+qvrLX+r6uPrbVWtZ7gz7t3Zi7OzMUrV64cdXkAAAAAHNKRQtHM/P4OItEPrbV+ZA//yuduKdvfH9njD1e3X/Xy2/bY77LWun+tdWGtdeHcuXNHWR4AAAAAT8BRPvVsqjdUP7vW+ttXHXqwuntv31396FXj37w//ewF1aevukUNAAAAgFN28xFe+9XVv1v9zMz8oz3216vXVG+bmXuqX6y+aR97Z/XS6lL1mepbj/DeAAAAAByzGw5Fa63/vZrHOPzCa8xf1Stv9P0AAAAAeHIdy6eeAQAAAPD5TygCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANiEIgAAAAAqoQgAAACATSgCAAAAoBKKAAAAANhuPu0FAAA8FZy/7x2nvQSu4eOvedlpLwEAPq8IRSfEXx7PJn95BAAAgH/OrWcAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVEIRAAAAAJtQBAAAAEAlFAEAAACwCUUAAAAAVHXzaS8AAACeLOfve8dpL4FH+fhrXnbaSwDgcbiiCAAAAIBKKAIAAABgc+sZAADAFzi3aQKf44oiAAAAACqhCAAAAIBNKAIAAACg8owiAADgBHkWDsDZ5ooiAAAAACqhCAAAAIBNKAIAAACgEooAAAAA2IQiAAAAACqhCAAAAIBNKAIAAACgEooAAAAA2G4+7QUAcPadv+8dp70EHuXjr3nZaS8BAICnIFcUAQAAAFAJRQAAAABsQhEAAAAAlVAEAAAAwHbioWhmXjwzPzczl2bmvpN+fwAAAACu7UQ/9Wxmbqp+oPrz1eXqAzPz4Frroye5DgD4fOeT6AAAeDKcaCiqnl9dWmt9rGpm3lrdVQlFQOUfvwAAAKfppG89u7V66Kr9y3sMAAAAgFN20lcUXdfM3Fvdu3f/n5n5udNczzG6pfrV014Ev9t832mvgGtwrsDhOFfgcJwrcDjOFTiE+b6nzLnyLz/WgZMORQ9Xt1+1f9se+/+tte6v7j/JRZ2Embm41rpw2uuAs865AofjXIHDca7A4ThX4HC+EM6Vk7717APVnTNzx8w8rXp59eAJrwEAAACAazjRK4rWWp+dmW+r3lXdVD2w1vrISa4BAAAAgGs78WcUrbXeWb3zpN/3DHjK3U4HTxLnChyOcwUOx7kCh+NcgcN5yp8rs9Y67TUAAAAAcAac9DOKAAAAADijhKJjNjMvnpmfm5lLM3PfNY4/fWZ+eB9//8ycP/lVwuk7xLnynTPz0Zn50My8Z2Ye8+Mb4anseufKVfP+nZlZM/OU/hQOeCyHOVdm5pv2ny0fmZn/7qTXCGfBIf4O9uyZ+fGZ+en997CXnsY64TTNzAMz88jMfPgxjs/MvG6fRx+ameed9BqfTELRMZqZm6ofqF5SPad6xcw851HT7qk+tdb68uq11fed7Crh9B3yXPnp6sJa649Xb6/+s5NdJZy+Q54rzcwfrr6jev/JrhDOhsOcKzNzZ/Wq6qvXWl9Z/ZUTXyicskP+ufKfVG9ba31VB59S/XdPdpVwJryxevHjHH9Jdef+urd6/Qms6cQIRcfr+dWltdbH1lq/Vb21uutRc+6q3rS33169cGbmBNcIZ8F1z5W11o+vtT6zd99X3XbCa4Sz4DB/rlR9bwf/8fAbJ7k4OEMOc678+9UPrLU+VbXWeuSE1whnwWHOlVX9i3v7i6v/8wTXB2fCWuu91ScfZ8pd1ZvXgfdVz5iZLzuZ1T35hKLjdWv10FX7l/fYNeestT5bfbr60hNZHZwdhzlXrnZP9Q+e1BXB2XTdc2Vf6nz7WusdJ7kwOGMO8+fKV1RfMTP/x8y8b2Ye73+K4anqMOfKf1r9pZm53MGnVX/7ySwNPq880X/PfF65+bQXAPB4ZuYvVReqf/u01wJnzcz8vupvV99yykuBzwc3d3CLwNd0cJXqe2fm31hr/fqprgrOnldUb1xr/Rcz86er/3ZmnrvW+p3TXhhwMlxRdLwerm6/av+2PXbNOTNzcweXc/7aiawOzo7DnCvNzJ+r/kb19Wut3zyhtcFZcr1z5Q9Xz61+YmY+Xr2getADrfkCdJg/Vy5XD661/tla6xeqf9pBOIIvJIc5V+6p3la11vqH1R+objmR1cHnj0P9e+bzlVB0vD5Q3Tkzd8zM0zp4+NuDj5rzYHX33v7G6sfWWusE1whnwXXPlZn5quq/7iASeY4EX6ge91xZa316rXXLWuv8Wut8B8/z+vq11sXTWS6cmsP8Hezvd3A1UTNzSwe3on3sJBcJZ8BhzpVfql5YNTP/egeh6MqJrhLOvgerb96ffvaC6tNrrU+c9qKOi1vPjtFa67Mz823Vu6qbqgfWWh+Zme+pLq61Hqze0MHlm5c6eDjWy09vxXA6Dnmu/K3qD1X//X7e+y+ttb7+1BYNp+CQ5wp8wTvkufKu6kUz89Hqt6v/eK3lqm6+oBzyXPmu6u/NzF/t4MHW3+I/tvlCMzNv6eA/F27Zz+t6dfX7q9Za/1UHz+96aXWp+kz1raez0ifHOOcBAAAAKLeeAQAAALAJRQAAAABUQhEAAAAAm1AEAAAAQCUUAQAAAHmf4FsAAAAcSURBVLAJRQAAAABUQhEAAAAAm1AEAAAAQFX/H4UkvTRm1Bd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting recall distribution \n",
    "recalls = calculate_recall_distribution(X_test, predictions, y_test)\n",
    "ids = [item[0] for item in recalls ]\n",
    "recalls = [item[1] for item in recalls ]\n",
    "recalls_df = pd.DataFrame(ids , columns=['id'])\n",
    "recalls_df['recalls']= recalls\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.hist(recalls_df['recalls'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform both training and testing sets \n",
    "training_features = lda.transform(train_vectors)\n",
    "testing_features = lda.transform(test_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
