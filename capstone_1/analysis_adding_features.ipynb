{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "import os\n",
    "from eval_funcs import *\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets from `analysis_no_features` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sparse matrices\n",
    "tf_idf_vectors = scipy.sparse.load_npz('./datasets/train_sparse_matrix.npz')\n",
    "X_test_tfidf = scipy.sparse.load_npz('./datasets/test_sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tfidf feature names list\n",
    "# if file exists we have already pickled a list\n",
    "if os.path.isfile(\"tfidf_features.txt\"):\n",
    "    with open(\"tfidf_features.txt\", 'rb') as f:\n",
    "        tfidf_feature_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load X_train and X_test\n",
    "X_train = pd.read_csv('./datasets/wikihow_X_train.csv') \n",
    "X_test = pd.read_csv('./datasets/wikihow_X_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load y_train and y_test \n",
    "y_train = pd.read_csv('./datasets/wikihow_y_train.csv', header = None) \n",
    "y_test = pd.read_csv('./datasets/wikihow_y_test.csv', header = None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructing Dataframes for analysis \n",
    "Let's add some features to see if our model performs better. We start by adding the sentences length feture to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ft = X_train[['sentence','sentence_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the sentence lengths array \n",
    "sent_lengths = np.array(X_train_ft['sentence_len'].values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14],\n",
       "       [ 9],\n",
       "       [11],\n",
       "       ...,\n",
       "       [ 7],\n",
       "       [ 9],\n",
       "       [14]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sentence lengths array to sparse matrix\n",
    "sparse_sent_lengths = scipy.sparse.csr_matrix(sent_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x1 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 70000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the two sparse arrays  \n",
    "X_train_feats = scipy.sparse.hstack([tf_idf_vectors,sparse_sent_lengths ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 94995)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the arrays  \n",
    "X_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same with test set \n",
    "X_test_ft = X_test[['sentence','sentence_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the sentence lengths array \n",
    "sent_lengths_test = np.array(X_test_ft['sentence_len'].values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sentence lengths array to sparse matrix\n",
    "sparse_sent_lengths_test = scipy.sparse.csr_matrix(sent_lengths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the two sparse arrays  \n",
    "X_test_feats = scipy.sparse.hstack([X_test_tfidf,sparse_sent_lengths_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 94995)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Cross-Validation with a Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "param_grid = {'alpha': (0.1, 1, 5, 10, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_CV = GridSearchCV(estimator=nb, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': (0.1, 1, 5, 10, 50)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_CV.fit(X_train_feats, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_CV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Naive Bayes with tf idf scores and sentence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nb_CV.predict(X_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[24809   258]\n",
      " [ 3114  1819]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     25067\n",
      "           1       0.88      0.37      0.52      4933\n",
      "\n",
      "    accuracy                           0.89     30000\n",
      "   macro avg       0.88      0.68      0.73     30000\n",
      "weighted avg       0.89      0.89      0.87     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Naive Bayes with BoW and sentence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performing Cross Validation for the best combination of parameters\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "X_train_dtm = vectorizer.fit_transform(X_train['sentence'])\n",
    "X_train_dtm_dense = X_train_dtm.toarray() \n",
    "len(X_train_dtm_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features to X_train_dtm and X_test_dtm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x99757 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1718399 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow_feats = scipy.sparse.hstack([X_train_dtm ,sparse_sent_lengths ])\n",
    "X_train_bow_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x99756 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 675443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vectorizer.transform(X_test['sentence'])\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x99757 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 705443 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow_feats =scipy.sparse.hstack([X_test_dtm ,sparse_sent_lengths_test ])\n",
    "X_test_bow_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform MultinomialNB Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bow = MultinomialNB(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_bow.fit(X_train_bow_feats, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_bow= nb_bow.predict(X_test_bow_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[23551  1516]\n",
      " [ 2022  2911]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, preds_bow)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     25067\n",
      "           1       0.66      0.59      0.62      4933\n",
      "\n",
      "    accuracy                           0.88     30000\n",
      "   macro avg       0.79      0.76      0.78     30000\n",
      "weighted avg       0.88      0.88      0.88     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, preds_bow)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** - For both classes we have pretty high precision although for class 1 it is lower than the precision for the same class with th multinomialNB classifier with no features (0.77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall (sensitivity)** - is the ratio of correctly predicted positive observations to the all observations in actual class, with adding the sentence length feature, we get a higher recall for class 1 (summary) as opposed to the same classifier without this feature (0.41)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 score** - F1 is usually more useful than accuracy, especially since we have an uneven class distribution. In our case, F1 score is 0.88, but we notice the the F1 score for the summary class has improved (0.62) compared to the model without the `sentence_len` feature (0.53)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the recall for the summary class here is significantly better probably because the MultinomialNB classifier works best with integers (suitable for classification with discrete features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the `tfidf_score` to the MultinomialNB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ft = X_train[['sentence_len', 'tfidf_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tfidf = np.array(X_train_ft['tfidf_score'].values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sentence tfidf array to sparse matrix\n",
    "sparse_sent_tfidf = scipy.sparse.csr_matrix(sent_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x99758 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1788390 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow_feats_1 = scipy.sparse.hstack([X_train_bow_feats ,sparse_sent_tfidf])\n",
    "X_train_bow_feats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for test set\n",
    "X_test_ft = X_test[['sentence','tfidf_score']]\n",
    "sent_tfidf_test = np.array(X_test_ft['tfidf_score'].values).reshape(-1, 1)\n",
    "#Converting sentence tfidf array to sparse matrix\n",
    "sparse_sent_tfidf_test = scipy.sparse.csr_matrix(sent_tfidf_test)\n",
    "#Concatenating the two sparse arrays  \n",
    "X_test_bow_feats_1 = scipy.sparse.hstack([X_test_bow_feats,sparse_sent_tfidf_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x99758 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 735440 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow_feats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bow_1 = MultinomialNB(alpha=0.1)\n",
    "nb_bow_1.fit(X_train_bow_feats_1, y_train)\n",
    "preds_bow_1= nb_bow_1.predict(X_test_bow_feats_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[23508  1559]\n",
      " [ 1472  3461]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, preds_bow_1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     25067\n",
      "           1       0.69      0.70      0.70      4933\n",
      "\n",
      "    accuracy                           0.90     30000\n",
      "   macro avg       0.82      0.82      0.82     30000\n",
      "weighted avg       0.90      0.90      0.90     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, preds_bow_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs even better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the `title_similarity` feature to the MultinomialNB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ft = X_train[['sentence_len', 'title_similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_len        4\n",
       "title_similarity    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ft[X_train_ft['title_similarity'] < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only have 3 negative values, let's try making them 0 and see if the model is better this way\n",
    "X_train_ft[X_train_ft['title_similarity'] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_len        0\n",
       "title_similarity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ft[X_train_ft['title_similarity'] < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_title_similarity = np.array(X_train_ft['title_similarity'].values).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sentence tfidf array to sparse matrix\n",
    "sparse_sent_title_similarity = scipy.sparse.csr_matrix(sent_title_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<70000x99759 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1858386 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow_feats_2 = scipy.sparse.hstack([X_train_bow_feats_1 ,sparse_sent_title_similarity])\n",
    "X_train_bow_feats_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for test set\n",
    "X_test_ft = X_test[['sentence','title_similarity']]\n",
    "sent_title_similarity_test = np.array(X_test_ft['title_similarity'].values).reshape(-1, 1)\n",
    "#Converting sentence tfidf array to sparse matrix\n",
    "sparse_sent_title_similarity_test = scipy.sparse.csr_matrix(sent_title_similarity_test)\n",
    "#Concatenating the two sparse arrays  \n",
    "X_test_bow_feats_2 = scipy.sparse.hstack([X_test_bow_feats_1,sparse_sent_title_similarity_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x99759 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 765438 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow_feats_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bow_2 = MultinomialNB(alpha=0.1)\n",
    "nb_bow_2.fit(X_train_bow_feats_2, y_train)\n",
    "preds_bow_2= nb_bow_2.predict(X_test_bow_feats_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[23491  1576]\n",
      " [ 1403  3530]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_test, preds_bow_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     25067\n",
      "           1       0.69      0.72      0.70      4933\n",
      "\n",
      "    accuracy                           0.90     30000\n",
      "   macro avg       0.82      0.83      0.82     30000\n",
      "weighted avg       0.90      0.90      0.90     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_test, preds_bow_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model give slighlty better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop what you re doing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best ways to calm down if you re al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sometimes, even taking a few seconds before yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Try counting to ten, or taking deep breaths, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Take a break</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For example, if an argument with your spouse i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I need to take a minute break before we contin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Go to a different place, focus on breathing de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I can do this</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Focus on your senses</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When we re stressed, sometimes our bodies inte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This stimulates the release of hormones like a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Over time, this panic response can become a ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Slowing down and focusing on the individual ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Studies also show that this conscious process ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  is_summary  predictions\n",
       "0                              Stop what you re doing           1            0\n",
       "1   One of the best ways to calm down if you re al...           0            0\n",
       "2   Sometimes, even taking a few seconds before yo...           0            0\n",
       "3   Try counting to ten, or taking deep breaths, b...           0            0\n",
       "4                                        Take a break           1            1\n",
       "5   For example, if an argument with your spouse i...           0            0\n",
       "6   I need to take a minute break before we contin...           0            0\n",
       "7   Go to a different place, focus on breathing de...           0            0\n",
       "8                                       I can do this           0            0\n",
       "9                                Focus on your senses           1            1\n",
       "10  When we re stressed, sometimes our bodies inte...           0            0\n",
       "11  This stimulates the release of hormones like a...           0            0\n",
       "12  Over time, this panic response can become a ha...           0            0\n",
       "13  Slowing down and focusing on the individual ph...           0            0\n",
       "14  Studies also show that this conscious process ...           0            0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval_funcs import *\n",
    "#New text never before seen and make predictions on it \n",
    "text_1_df = pd.read_csv('./datasets/text_1.csv')\n",
    "text_1_vectors = vectorizer.transform(text_1_df['sentence'])\n",
    "text_1_df['title_similarity'] = text_1_df.apply(lambda x: get_similarity(x['sentence'], x['title']), axis=1)\n",
    "text_1_feat = prediction_preprocessing(text_1_df)\n",
    "text_1_full_feats = scipy.sparse.hstack([text_1_vectors,text_1_feat])\n",
    "pred_text_1 = nb_bow_2.predict(text_1_full_feats)\n",
    "results_text_1 = text_1_df[['sentence','is_summary']]\n",
    "results_text_1['predictions'] = pred_text_1\n",
    "results_text_1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate recall for text 1\n",
    "len(results_text_1[(results_text_1['is_summary'] == results_text_1['predictions'])&(results_text_1['predictions']==1)])\n",
    "len(results_text_1[results_text_1['is_summary']==1])\n",
    "\n",
    "recall_text_1 = len(results_text_1[(results_text_1['is_summary'] == results_text_1['predictions'])&(results_text_1['predictions']==1)])/len(results_text_1[results_text_1['is_summary']==1])\n",
    "recall_text_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Know that everyone has their own unique experi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No one else will grieve in exactly the same wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you feel like you are reacting differently ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allow yourself to feel your own unique emotion...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is no typical loss, which means there is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sudden losses, such as those due to trauma, ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acknowledge that there are many kinds of loss</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Death is a loss we must all deal with at some ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>However, it is not the only type of loss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You can mourn the ending of a relationship or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It could be the realization that a cherished d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Everyone is entitled to their own grief, regar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Do not be afraid to mourn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Acknowledge your emotions as a natural response</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>There are many losses you may experience in life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  is_summary  predictions\n",
       "0   Know that everyone has their own unique experi...           1            0\n",
       "1   No one else will grieve in exactly the same wa...           0            0\n",
       "2   If you feel like you are reacting differently ...           0            0\n",
       "3   Allow yourself to feel your own unique emotion...           0            0\n",
       "4   There is no typical loss, which means there is...           0            0\n",
       "5   Sudden losses, such as those due to trauma, ac...           0            0\n",
       "6       Acknowledge that there are many kinds of loss           1            0\n",
       "7   Death is a loss we must all deal with at some ...           0            0\n",
       "8            However, it is not the only type of loss           0            0\n",
       "9   You can mourn the ending of a relationship or ...           0            0\n",
       "10  It could be the realization that a cherished d...           0            0\n",
       "11  Everyone is entitled to their own grief, regar...           0            0\n",
       "12                          Do not be afraid to mourn           0            0\n",
       "13    Acknowledge your emotions as a natural response           0            1\n",
       "14   There are many losses you may experience in life           0            0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New text never before seen and make predictions on it \n",
    "text_2_df = pd.read_csv('./datasets/text_2.csv')\n",
    "text_2_vectors = vectorizer.transform(text_2_df['sentence'])\n",
    "text_2_df['title_similarity'] = text_2_df.apply(lambda x: get_similarity(x['sentence'], x['title']), axis=1)\n",
    "text_2_feat = prediction_preprocessing(text_2_df)\n",
    "text_2_full_feats = scipy.sparse.hstack([text_2_vectors,text_2_feat])\n",
    "pred_text_2 = nb_bow_2.predict(text_2_full_feats)\n",
    "results_text_2 = text_2_df[['sentence','is_summary']]\n",
    "results_text_2['predictions'] = pred_text_2\n",
    "results_text_2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5161290322580645"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate recall for text 2\n",
    "len(results_text_2[(results_text_2['is_summary'] == results_text_2['predictions'])&(results_text_2['predictions']==1)])\n",
    "len(results_text_2[results_text_2['is_summary']==1])\n",
    "\n",
    "recall_text_2 = len(results_text_2[(results_text_2['is_summary'] == results_text_2['predictions'])&(results_text_2['predictions']==1)])/len(results_text_2[results_text_2['is_summary']==1])\n",
    "recall_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think about the time commitment of ferret proo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Before you get a ferret, you will need to spen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You will have to run many errands gathering su...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the event you move, you will have to repeat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Be honest with yourself about whether you have...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You will have to fill in any holes or gaps in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You will also have to hide heavier objects, li...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ferrets love to climb, and can knock such obje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Staircases need to be blocked off, and househo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ferrets will chew such objects</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cleaning and upkeep of your home will be more ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ferrets will chew almost anything, and can get...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Therefore, you will have to keep your home ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>See if you have enough time to play with a ferret</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ferrets are social animals</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  is_summary  predictions\n",
       "0   Think about the time commitment of ferret proo...           1            1\n",
       "1   Before you get a ferret, you will need to spen...           0            0\n",
       "2   You will have to run many errands gathering su...           0            0\n",
       "3   In the event you move, you will have to repeat...           0            0\n",
       "4   Be honest with yourself about whether you have...           0            1\n",
       "5   You will have to fill in any holes or gaps in ...           0            0\n",
       "6   You will also have to hide heavier objects, li...           0            0\n",
       "7   Ferrets love to climb, and can knock such obje...           0            0\n",
       "8   Staircases need to be blocked off, and househo...           0            0\n",
       "9                      Ferrets will chew such objects           0            0\n",
       "10  Cleaning and upkeep of your home will be more ...           0            0\n",
       "11  Ferrets will chew almost anything, and can get...           0            0\n",
       "12  Therefore, you will have to keep your home ver...           0            0\n",
       "13  See if you have enough time to play with a ferret           1            0\n",
       "14                         Ferrets are social animals           0            0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New text never before seen and make predictions on it \n",
    "text_3_df = pd.read_csv('./datasets/text_3.csv')\n",
    "text_3_vectors = vectorizer.transform(text_3_df['sentence'])\n",
    "text_3_df['title_similarity'] = text_3_df.apply(lambda x: get_similarity(x['sentence'], x['title']), axis=1)\n",
    "text_3_feat = prediction_preprocessing(text_3_df)\n",
    "text_3_full_feats = scipy.sparse.hstack([text_3_vectors,text_3_feat])\n",
    "pred_text_3 = nb_bow_2.predict(text_3_full_feats)\n",
    "results_text_3 = text_3_df[['sentence','is_summary']]\n",
    "results_text_3['predictions'] = pred_text_3\n",
    "results_text_3.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate recall for text 3\n",
    "len(results_text_3[(results_text_3['is_summary'] == results_text_3['predictions'])&(results_text_3['predictions']==1)])\n",
    "len(results_text_3[results_text_3['is_summary']==1])\n",
    "\n",
    "recall_text_3 = len(results_text_3[(results_text_3['is_summary'] == results_text_3['predictions'])&(results_text_3['predictions']==1)])/len(results_text_3[results_text_3['is_summary']==1])\n",
    "recall_text_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the recalls accross articles and evaluate the recall distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = calculate_recall_distribution(X_test, preds_bow_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [item[0] for item in recalls ]\n",
    "recalls = [item[1] for item in recalls ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls_df = pd.DataFrame(ids , columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls_df['recalls']= recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4355</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4356</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4357</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4358</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5094</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6245</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7522</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7523</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7925</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7926</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7962</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8142</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8243</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  recalls\n",
       "0   4354      1.0\n",
       "1   4355      1.0\n",
       "2   4356      NaN\n",
       "3   4357      1.0\n",
       "4   4358      1.0\n",
       "5   5009      1.0\n",
       "6   5010      1.0\n",
       "7   5011      0.0\n",
       "8   5094      1.0\n",
       "9   6245      0.0\n",
       "10  7522      NaN\n",
       "11  7523      1.0\n",
       "12  7924      NaN\n",
       "13  7925      0.5\n",
       "14  7926      NaN\n",
       "15  7962      0.4\n",
       "16  8142      1.0\n",
       "17  8143      NaN\n",
       "18  8144      NaN\n",
       "19  8243      1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.hist(recalls_df['recalls'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         471\n",
       "recalls      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls_df[recalls_df['recalls'].isnull() == True].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         2048\n",
       "recalls    2048\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls_df[recalls_df['recalls'].isnull() == False].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LDA for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=10,random_state=42)\n",
    "#fit model to the training data\n",
    "#X_train_dtm.toarray().shape\n",
    "lda_dtf = lda.fit_transform(X_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KMeans on these modelled topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "       n_clusters=2, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(lda_dtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_preds = model.predict(lda_dtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsupervised_preds.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[14603 43747]\n",
      " [ 2049  9601]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n {metrics.confusion_matrix(y_train, unsupervised_preds.reshape(-1,1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.25      0.39     58350\n",
      "           1       0.18      0.82      0.30     11650\n",
      "\n",
      "    accuracy                           0.35     70000\n",
      "   macro avg       0.53      0.54      0.34     70000\n",
      "weighted avg       0.76      0.35      0.37     70000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Classification Report: \\n\\n {metrics.classification_report(y_train, unsupervised_preds.reshape(-1,1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision here is very low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use LDA with Logistic Regression for classification "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
